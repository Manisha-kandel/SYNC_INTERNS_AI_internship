{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Import Libraries","metadata":{}},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\nimport pandas as pd \nimport PIL  \nimport tensorflow as tf\nimport itertools\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n\nimport os  \nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau  \n\nfrom glob import glob\nimport pathlib","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:35:30.593601Z","iopub.execute_input":"2023-04-04T17:35:30.594006Z","iopub.status.idle":"2023-04-04T17:35:30.601864Z","shell.execute_reply.started":"2023-04-04T17:35:30.593970Z","shell.execute_reply":"2023-04-04T17:35:30.599840Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Reading Data","metadata":{}},{"cell_type":"code","source":"data_dir = '/kaggle/input/plantvillage-dataset'\ncolor_dir = os.path.join(data_dir, 'color')\ncolor_dir = pathlib.Path(color_dir)  ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:35:33.815312Z","iopub.execute_input":"2023-04-04T17:35:33.816272Z","iopub.status.idle":"2023-04-04T17:35:33.822175Z","shell.execute_reply.started":"2023-04-04T17:35:33.816232Z","shell.execute_reply":"2023-04-04T17:35:33.820940Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Sample leaves\nc_Apple__healthy = list(color_dir.glob('Apple___healthy/*'))\nprint('Apple__healthy')\ndisplay(PIL.Image.open(str(c_Apple__healthy[0])))\ndisplay(PIL.Image.open(str(c_Apple__healthy[7])))","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:35:35.010513Z","iopub.execute_input":"2023-04-04T17:35:35.010998Z","iopub.status.idle":"2023-04-04T17:35:35.084443Z","shell.execute_reply.started":"2023-04-04T17:35:35.010960Z","shell.execute_reply":"2023-04-04T17:35:35.083219Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define functions to \n* make filepath-label-dataframe\n* split data to train, valid and test\n* create generators from the train, valid and test data. \n* show sample images using the generators. ","metadata":{}},{"cell_type":"code","source":"# Generate data paths and labels dataframe. \ndef make_path_label_df(data_dir):\n    '''\n    - takes the path to the data directory  \n    - returns a dataframe: with filepath and labels for each image.'''\n    \n    filepaths = []\n    labels = []\n\n    folders = os.listdir(data_dir)\n    for folder in folders:\n        folderpath = os.path.join(data_dir, folder)\n        files = os.listdir(folderpath)\n        for file in files:\n            filepath = os.path.join(folderpath, file)\n            filepaths.append(filepath)\n            labels.append(folder)\n\n    Filepath_series = pd.Series(filepaths, name= 'filepaths')\n    Label_series = pd.Series(labels, name='labels')\n    dataframe = pd.concat([Filepath_series, Label_series], axis= 1)\n    return dataframe\n\n# Split dataframe to train, valid, and test\ndef split_to_train_valid_test(data_dir):\n    '''\n    - takes the path to the data directory\n    - returns the three dataframes(train, valid and test respectively) containing the file paths and labels for each set.'''\n    # train dataframe\n    df = make_path_label_df(data_dir)\n    print('Displaying sample of Dataframe with filenames and labels')\n    display(df.sample(10))\n    strat = df['labels']                                                \n    train_df, dummy_df = train_test_split(df,  train_size= 0.8, shuffle= True, random_state= 42, stratify= strat)     #Note stratify=strat\n\n    # valid and test dataframe\n    strat = dummy_df['labels']\n    valid_df, test_df = train_test_split(dummy_df,  train_size= 0.5, shuffle= True, random_state= 42, stratify= strat)\n    print('Train, valid, test dataframe created:')\n    print('Train dataframe sample: ')\n    display(train_df.sample(2))\n    print('|'+'-'*80+'|')\n    print('valid dataframe sample: ')\n    display(valid_df.sample(2))\n    print('|'+'-'*80+'|')\n    print('test dataframe sample: ')\n    display(test_df.sample(2))\n    print('|'+'-'*80+'|')\n\n    return train_df, valid_df, test_df","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:35:46.175117Z","iopub.execute_input":"2023-04-04T17:35:46.176050Z","iopub.status.idle":"2023-04-04T17:35:46.187949Z","shell.execute_reply.started":"2023-04-04T17:35:46.175993Z","shell.execute_reply":"2023-04-04T17:35:46.186825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#create generators for given dataframes. \ndef make_generators(train_df, valid_df, test_df, batch_size):\n    '''\n    This function takes train, validation, and test dataframe and fit them into image data generator, because model takes data from image data generator.\n    Image data generator converts images into tensors. '''\n\n    # define model parameters\n    img_size = (224, 224)\n    channels = 3      \n    color = 'rgb'\n    img_shape = (224, 224, 3)\n\n    #test_batch_size and test_steps\n    test_df_length = len(test_df)    \n    test_batch_size = 8               \n    test_steps = test_df_length // test_batch_size\n    \n\n    #Function to return image as it is\n    def identity(img):\n        return img\n\n    t_gen = ImageDataGenerator(preprocessing_function= identity, horizontal_flip= True)              \n    vt_gen = ImageDataGenerator(preprocessing_function= identity)                    \n\n    train_gen = t_gen.flow_from_dataframe( train_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',     \n                                        color_mode= color, shuffle= True, batch_size= batch_size)\n\n    valid_gen = vt_gen.flow_from_dataframe( valid_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode= color, shuffle= True, batch_size= batch_size)\n\n    # Note: we will use custom test_batch_size, and make shuffle= false\n    test_gen = vt_gen.flow_from_dataframe( test_df, x_col= 'filepaths', y_col= 'labels', target_size= img_size, class_mode= 'categorical',\n                                        color_mode= color, shuffle= False, batch_size= test_batch_size)       \n\n    return train_gen, valid_gen, test_gen","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:35:52.125117Z","iopub.execute_input":"2023-04-04T17:35:52.125482Z","iopub.status.idle":"2023-04-04T17:35:52.134361Z","shell.execute_reply.started":"2023-04-04T17:35:52.125447Z","shell.execute_reply":"2023-04-04T17:35:52.133287Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def show_samples(generator):\n    '''\n    This function take the data generator and show sample of the images\n    '''\n\n    # return classes , images to be displayed\n    g_dict = generator.class_indices        \n    classes = list(g_dict.keys())     \n    images, labels = next(generator)  \n\n    # calculate number of displayed samples\n    length = len(labels)       \n    sample = min(length, 20)    \n\n    plt.figure(figsize= (25, 20))\n\n    for i in range(sample):\n        #show image\n        plt.subplot(4, 5, (i + 1))\n        image = images[i] / 255       # scale pixels\n        plt.imshow(image)\n        # get class of image\n        index = np.argmax(labels[i])  \n        class_name = classes[index]   \n        plt.title(class_name, color= 'purple', fontsize= 12)\n        plt.subplots_adjust(hspace=0.1, wspace=0.6)       \n        plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:36:05.898405Z","iopub.execute_input":"2023-04-04T17:36:05.898798Z","iopub.status.idle":"2023-04-04T17:36:05.908208Z","shell.execute_reply.started":"2023-04-04T17:36:05.898747Z","shell.execute_reply":"2023-04-04T17:36:05.906519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Creating generators","metadata":{}},{"cell_type":"code","source":"data_directory = color_dir \n\n# Get splitted data\ntrain_df, valid_df, test_df = split_to_train_valid_test(data_directory)\n\n# Get Generators\ntrain_gen, valid_gen, test_gen = make_generators(train_df, valid_df, test_df, batch_size = 32)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:36:22.628212Z","iopub.execute_input":"2023-04-04T17:36:22.628821Z","iopub.status.idle":"2023-04-04T17:36:47.656985Z","shell.execute_reply.started":"2023-04-04T17:36:22.628754Z","shell.execute_reply":"2023-04-04T17:36:47.655712Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualizing image samples","metadata":{}},{"cell_type":"code","source":"show_samples(train_gen)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:36:59.035243Z","iopub.execute_input":"2023-04-04T17:36:59.036029Z","iopub.status.idle":"2023-04-04T17:37:01.617425Z","shell.execute_reply.started":"2023-04-04T17:36:59.035989Z","shell.execute_reply":"2023-04-04T17:37:01.616437Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define and compile model\n* We will use 'EfficientNetB3' as the base model. \n* Lower layers will be freezed.\n* Upper 80 layers will be trained.","metadata":{}},{"cell_type":"code","source":"# Create Model Structure\nimg_shape=(224,224,3)\nclass_count = len(list(train_gen.class_indices.keys())) \n\n# For transfer learning, will use efficientnetb3 from EfficientNet family.\nbase_model = tf.keras.applications.efficientnet.EfficientNetB3(include_top= False, weights= \"imagenet\", input_shape= img_shape, pooling= 'max')            #transfer learning\nbase_model.trainable = True\n\n# Freeze all layers except for the last 80 layers.\nfor layer in base_model.layers[:-80]:\n    layer.trainable = False\n\nmodel = Sequential([\n    base_model,\n    layers.BatchNormalization(axis= -1, momentum= 0.99, epsilon= 0.001),\n    layers.Dense(256, kernel_regularizer= keras.regularizers.l2(l= 0.01), activity_regularizer= keras.regularizers.l1(0.001),\n                bias_regularizer= keras.regularizers.l1(0.001), activation= 'relu'),\n    layers.Dropout(rate= 0.4, seed= 42),\n    layers.Dense(class_count, activation= 'softmax')\n])\n\nmodel.compile(keras.optimizers.Adamax(learning_rate= 0.0005), loss= 'categorical_crossentropy', metrics= ['accuracy'])       \n\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:37:45.578808Z","iopub.execute_input":"2023-04-04T17:37:45.579852Z","iopub.status.idle":"2023-04-04T17:37:49.844542Z","shell.execute_reply.started":"2023-04-04T17:37:45.579748Z","shell.execute_reply":"2023-04-04T17:37:49.843433Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define callbacks and fit the model","metadata":{}},{"cell_type":"code","source":"batch_size = 32   \nepochs = 10                 \nlr_patience = 1   \nearly_stop_patience = 2   \nfactor = 0.5   \n\n# Define the callbacks\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=early_stop_patience,\n                           verbose=1, \n                           mode='min', \n                           baseline=None,\n                           restore_best_weights=True\n                          )\nlr_reduction_on_plateau = ReduceLROnPlateau(monitor='accuracy',\n                                            patience=lr_patience,\n                                            factor=factor)\ncallback_list = [early_stop, lr_reduction_on_plateau]          ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:38:02.003956Z","iopub.execute_input":"2023-04-04T17:38:02.004580Z","iopub.status.idle":"2023-04-04T17:38:02.014869Z","shell.execute_reply.started":"2023-04-04T17:38:02.004530Z","shell.execute_reply":"2023-04-04T17:38:02.013664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x= train_gen, epochs= epochs, verbose=1, callbacks= callback_list,\n                    validation_data= valid_gen, validation_steps= None, shuffle= False)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T17:38:05.909498Z","iopub.execute_input":"2023-04-04T17:38:05.909995Z","iopub.status.idle":"2023-04-04T18:15:19.269694Z","shell.execute_reply.started":"2023-04-04T17:38:05.909957Z","shell.execute_reply":"2023-04-04T18:15:19.268681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Define functions to \n* Plot training history\n* Plot Confusion matrix \n* Plot Classification Report\n* Visualize Predictions","metadata":{}},{"cell_type":"code","source":"def plot_training_history(history_):               \n    '''\n    This function receives a trained model's history as input and generates a plot that displays the \n    accuracy and loss histories of the model, highlighting the best epoch for both metrics.\n    '''\n\n    # Define needed variables\n    tr_acc = history_.history['accuracy']\n    tr_loss = history_.history['loss']\n    val_acc = history_.history['val_accuracy']\n    val_loss = history_.history['val_loss']\n    \n    min_loss_index = np.argmin(val_loss)\n    max_acc_index = np.argmax(val_acc)\n    val_lowest = val_loss[min_loss_index]\n    acc_highest = val_acc[max_acc_index]\n    \n    Epoch_numbers = [i+1 for i in range(len(tr_acc))]\n    \n    loss_label = f'best epoch= {str(min_loss_index + 1)}'\n    acc_label = f'best epoch= {str(max_acc_index + 1)}'\n\n    # Plot training history\n    sns.set_style(\"whitegrid\")\n    plt.figure(figsize=(20, 8))\n\n    plt.subplot(1, 2, 1)\n    sns.lineplot(x=Epoch_numbers, y=tr_loss, color='r', label='Training loss')\n    sns.lineplot(x=Epoch_numbers, y=val_loss, color='b', label='Validation loss')\n    plt.scatter(min_loss_index + 1, val_lowest, s= 250, c= 'green', alpha=0.3, label= loss_label)\n    plt.title('Training and Validation Losses')\n    plt.xlabel('Number of Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    sns.lineplot(x=Epoch_numbers, y=tr_acc, color='r', label='Training Accuracy')\n    sns.lineplot(x=Epoch_numbers, y=val_acc, color='b', label='Validation Accuracy')\n    plt.scatter(max_acc_index + 1 , acc_highest, s= 250, c= 'green', alpha=0.3, label= acc_label)\n    plt.title('Training and Validation Accuracies')\n    plt.xlabel('Number of Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.tight_layout()\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:15:48.013715Z","iopub.execute_input":"2023-04-04T18:15:48.014115Z","iopub.status.idle":"2023-04-04T18:15:48.026764Z","shell.execute_reply.started":"2023-04-04T18:15:48.014082Z","shell.execute_reply":"2023-04-04T18:15:48.025692Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_confusion_matrix(generator, y_true, y_pred):\n    #let's plot confusion matrix\n    import itertools\n    sns.set_style('white')\n    # Get the class indices and labels\n    g_dict = generator.class_indices\n    classes = list(g_dict.keys())\n\n    cm = confusion_matrix(y_true, y_pred)\n\n    # Plot the confusion matrix\n    plt.figure(figsize=(25,25))\n    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Greens, vmin=0, vmax=1)   #--> TRY IT..\n    plt.title('Confusion matrix')\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    # Normalize the confusion matrix\n    cm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n    text_color = (0.5, 0.7, 0.5)\n\n    # Plot the normalized confusion matrix\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, \"{:.2f}\".format(cm_norm[i, j]),\n                 horizontalalignment=\"center\",\n                 color=text_color)                \n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:16:09.041098Z","iopub.execute_input":"2023-04-04T18:16:09.041958Z","iopub.status.idle":"2023-04-04T18:16:09.057693Z","shell.execute_reply.started":"2023-04-04T18:16:09.041903Z","shell.execute_reply":"2023-04-04T18:16:09.056292Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_classification_report(y_true, y_pred, classes):\n    report = classification_report(y_true, y_pred, target_names=classes, output_dict=True)\n    report_df = report_df = pd.DataFrame(report)      \n    # Plot heatmap\n    plt.figure(figsize=(6, 15))\n    ax = sns.heatmap(report_df.iloc[:-1, :-3].T, cmap='Blues', annot=True, fmt='.2f', cbar=False)\n    ax.set_title('Classification Report')\n    ax.set_xlabel('Metrics')\n    ax.set_ylabel('Classes')\n    plt.xticks(rotation=90, ha='right')\n    plt.show()\n","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:16:12.482884Z","iopub.execute_input":"2023-04-04T18:16:12.483255Z","iopub.status.idle":"2023-04-04T18:16:12.491086Z","shell.execute_reply.started":"2023-04-04T18:16:12.483223Z","shell.execute_reply":"2023-04-04T18:16:12.489864Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def visualize_predictions(test_generator, pred_generator):\n    '''This function is suited to test_generator that has batch_size of 8.'''\n    #make a list of 8 next predictions using generator\n    pred_values = []\n    for i in range(8):                                 \n        pred_values.append(next(pred_generator))\n    \n    # return classes , images to be displayed\n    g_dict = test_generator.class_indices        \n    classes = list(g_dict.keys())\n    images, labels = next(test_generator)\n\n    #specify length\n    length = 8\n\n    plt.figure(figsize= (28, 12))\n\n    for i in range(length):\n        #show image\n        plt.subplot(2, 4, (i + 1))\n        image = images[i] / 255       # scale pixels\n        plt.imshow(image)\n        # get class of image\n        # get class of image\n        index_true = np.argmax(labels[i])  \n        class_name_true = classes[index_true] \n        class_name_pred = classes[pred_values[i]]\n        plt.title(f'Actual: {class_name_true}\\nPredicted: {class_name_pred}', color= 'purple', fontsize= 14)\n        plt.subplots_adjust(hspace=0.3, wspace=0.1)       \n        plt.axis('off')\n    plt.show()\n    ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:00:19.931287Z","iopub.execute_input":"2023-04-04T19:00:19.932177Z","iopub.status.idle":"2023-04-04T19:00:19.940458Z","shell.execute_reply.started":"2023-04-04T19:00:19.932139Z","shell.execute_reply":"2023-04-04T19:00:19.939257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot the training history. ","metadata":{}},{"cell_type":"code","source":"#Let's use the function defined above.\nplot_training_history(history)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:16:20.490986Z","iopub.execute_input":"2023-04-04T18:16:20.491348Z","iopub.status.idle":"2023-04-04T18:16:21.218376Z","shell.execute_reply.started":"2023-04-04T18:16:20.491315Z","shell.execute_reply":"2023-04-04T18:16:21.216829Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Evaluate scores on train, valid and test sets.","metadata":{}},{"cell_type":"code","source":"test_df_length = len(test_df)\ntrain_df_length = len(train_df)\nvalid_df_length = len(valid_df)\ntest_batch_size = 8                 \ntest_steps = test_df_length // test_batch_size    \ntrain_steps = train_df_length // 32\nvalid_steps = valid_df_length // 32\n\n#evaluate scores\ntrain_score = model.evaluate(train_gen, steps= train_steps, verbose= 1)\nvalid_score = model.evaluate(valid_gen, steps= valid_steps, verbose= 1)\ntest_score = model.evaluate(test_gen, steps= test_steps, verbose= 1)\n\n# Print scores\nprint('|'+'-' * 40+'|')\nprint(\"Train Loss: \", train_score[0])\nprint(\"Train Accuracy: \", train_score[1])\nprint('|'+'-' * 40+'|')\n\nprint(\"Validation Loss: \", valid_score[0])\nprint(\"Validation Accuracy: \", valid_score[1])\nprint('|'+'-' * 40+'|')\n\nprint(\"Test Loss: \", test_score[0])\nprint(\"Test Accuracy: \", test_score[1])","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:17:59.832218Z","iopub.execute_input":"2023-04-04T18:17:59.833154Z","iopub.status.idle":"2023-04-04T18:21:27.843251Z","shell.execute_reply.started":"2023-04-04T18:17:59.833100Z","shell.execute_reply":"2023-04-04T18:21:27.841989Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Plot Classification Report and Confusion Matrix ","metadata":{}},{"cell_type":"code","source":"y_true = test_gen.classes\npreds = model.predict(test_gen)       \ny_pred = np.argmax(preds, axis=1)\n\ng_dict = test_gen.class_indices\nclasses = list(g_dict.keys())","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:21:45.054151Z","iopub.execute_input":"2023-04-04T18:21:45.055147Z","iopub.status.idle":"2023-04-04T18:22:10.637030Z","shell.execute_reply.started":"2023-04-04T18:21:45.055094Z","shell.execute_reply":"2023-04-04T18:22:10.635978Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_classification_report(y_true, y_pred, classes)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:22:21.821327Z","iopub.execute_input":"2023-04-04T18:22:21.821698Z","iopub.status.idle":"2023-04-04T18:22:23.642610Z","shell.execute_reply.started":"2023-04-04T18:22:21.821664Z","shell.execute_reply":"2023-04-04T18:22:23.641596Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plot_confusion_matrix(test_gen, y_true, y_pred)    ","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:22:45.300829Z","iopub.execute_input":"2023-04-04T18:22:45.301678Z","iopub.status.idle":"2023-04-04T18:22:51.667387Z","shell.execute_reply.started":"2023-04-04T18:22:45.301637Z","shell.execute_reply":"2023-04-04T18:22:51.666496Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Visualize Predictions","metadata":{}},{"cell_type":"code","source":"test_gen.reset()\npred_gen = (x for x in y_pred)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T18:53:16.763238Z","iopub.execute_input":"2023-04-04T18:53:16.763605Z","iopub.status.idle":"2023-04-04T18:53:16.768444Z","shell.execute_reply.started":"2023-04-04T18:53:16.763571Z","shell.execute_reply":"2023-04-04T18:53:16.767384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_predictions(test_gen, pred_gen)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:00:25.747582Z","iopub.execute_input":"2023-04-04T19:00:25.748265Z","iopub.status.idle":"2023-04-04T19:00:27.361363Z","shell.execute_reply.started":"2023-04-04T19:00:25.748224Z","shell.execute_reply":"2023-04-04T19:00:27.360387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"visualize_predictions(test_gen, pred_gen)","metadata":{"execution":{"iopub.status.busy":"2023-04-04T19:01:05.278014Z","iopub.execute_input":"2023-04-04T19:01:05.279245Z","iopub.status.idle":"2023-04-04T19:01:07.176593Z","shell.execute_reply.started":"2023-04-04T19:01:05.279196Z","shell.execute_reply":"2023-04-04T19:01:07.175457Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}